{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f78c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re, nltk\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70119176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>AMH</th>\n",
       "      <th>Tigrinya</th>\n",
       "      <th>Lithaunian</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>czech</th>\n",
       "      <th>Germany</th>\n",
       "      <th>French</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>4 Babette 3 Miss Patty 2 Richard 1 LANE Gilmor...</td>\n",
       "      <td>4 ባቤት 3 ወይዘሪት ትዕግስት 2 ሪቻርድ 1 ሌን ጊልሞርግልብርቲ4</td>\n",
       "      <td>4 ባቤት 3 ወይዘሪት ትዕግስቲ 2 ሪቻርድ 1 ሎምን ጊልሞርጊስ</td>\n",
       "      <td>4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...</td>\n",
       "      <td>4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...</td>\n",
       "      <td>4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...</td>\n",
       "      <td>4 Babette 3 Fräulein Patty 2 Richard 1 Lane Gi...</td>\n",
       "      <td>4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>I guess you need a reading lesson Charlie</td>\n",
       "      <td>የንባብ ትምህርት ቻርሊ እንደሚያስፈልግህ እገምታለሁ</td>\n",
       "      <td>ናይ ንባብ ትምህርቲ ከም ዘድልየኻ ይግምት እየ ቻርሊ</td>\n",
       "      <td>Manau, jums reikia skaitymo pamokos Charlie</td>\n",
       "      <td>أعتقد أنك بحاجة إلى درس في القراءة تشارلي</td>\n",
       "      <td>Myslím, že potřebujete lekci čtení Charlie</td>\n",
       "      <td>Ich denke du brauchst eine Lesestunde Charlie</td>\n",
       "      <td>Je suppose que tu as besoin d'une leçon de lec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>if this were true it would be good Because Ass...</td>\n",
       "      <td>ይህ እውነት ቢሆን ኖሮ አሳንጅ በማሪን ሌ ፔን ኢላማ ላይ ያነጣጠረ በመሆ...</td>\n",
       "      <td>ከምኡ እንተ ዝኸውን ነይሩ ፡ ኣሳንጅ ንሓለዋ ባሕሪ ዒላማ ምገበረ ነይሩ</td>\n",
       "      <td>Jei tai būtų tiesa, tai būtų gerai, nes Assang...</td>\n",
       "      <td>إذا كان هذا صحيحًا ، فسيكون ذلك جيدًا لأن أسان...</td>\n",
       "      <td>Kdyby to byla pravda, bylo by to dobré, protož...</td>\n",
       "      <td>Wenn dies wahr wäre, wäre es gut, weil Assange...</td>\n",
       "      <td>Si cela était vrai, ce serait bien car Assange...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>probably going to hell for this as well but po...</td>\n",
       "      <td>ምናልባትም ይህን ለማድረግ ወደ ሲኦል ቢሄድም ሊቀ ጳጳስ ፍራንሲስ ግን ከ...</td>\n",
       "      <td>ምናልባት ናብ ሲኦል ምኻድ ከምኡ እውን ጳጳስ ፍራንሲስ ናብ ቫቲካን ፈንጠ...</td>\n",
       "      <td>Tikriausiai taip pat eidami į pragarą, tačiau ...</td>\n",
       "      <td>من المحتمل أن يذهب إلى الجحيم من أجل هذا أيضًا...</td>\n",
       "      <td>Pravděpodobně za to také chodím do pekla, ale ...</td>\n",
       "      <td>Wahrscheinlich auch dafür zur Hölle, aber Paps...</td>\n",
       "      <td>Aller probablement en enfer pour cela aussi, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>He didnt fight anything thats his excuse just ...</td>\n",
       "      <td>ልክ እንደ ቻቬዝ ሰበብ የሆነውን ማንኛውንም ነገር ተጋድሎ አድርጓል ፤ ማ...</td>\n",
       "      <td>ምኽኒት ቻቬዝ ፡ ከምኡ ድማ ማዱሮስ ምኽኒት ምስ ኣቕረበ ፡ ነቲ ዘቕረቦ ...</td>\n",
       "      <td>Jis nieko nekovojo, tai yra jo pasiteisinimas,...</td>\n",
       "      <td>لم يحارب أي شيء هذا عذرا مثلما كان عذر شافيز و...</td>\n",
       "      <td>Nebojoval s ničím, co je jeho omluva, stejně j...</td>\n",
       "      <td>Er kämpfte nicht gegen etwas, was seine Entsch...</td>\n",
       "      <td>Il n'a pas combattu quoi que ce soit, c'est so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>Even though i have my personal beliefs about a...</td>\n",
       "      <td>ፅንስ ስለማስወርድ የግል እምነቴ ቢኖረኝም እንኳ ሌሎች መብቶችን እንደማላ...</td>\n",
       "      <td>ዋላ \"ኳ ብዛዕባ ምንጻል ጥንሲ ውልቃዊ እምነተይ እንተሃለወኒ ፡ ኣብ ልዕ...</td>\n",
       "      <td>Nors aš turiu savo asmeninių įsitikinimų apie ...</td>\n",
       "      <td>على الرغم من أن لدي معتقداتي الشخصية حول الإجه...</td>\n",
       "      <td>I když mám své osobní přesvědčení o potratech,...</td>\n",
       "      <td>Obwohl ich meine persönlichen Überzeugungen üb...</td>\n",
       "      <td>Même si j'ai mes convictions personnelles sur ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>if tim duncan played one more season we wouldv...</td>\n",
       "      <td>አንድ ተጨማሪ ወቅት ላይ ዶንሰን ቢጫወት ኖሮ 21 ክዳን እናስቀምጠው ነበር</td>\n",
       "      <td>ግዜ ዝደኸመ ዳንከን ኣብ ሓደ ወቕቲ እንተ ዝጻወት ፡ 21 መድሓኒ ምበልና...</td>\n",
       "      <td>Jei Timas Duncanas žaidė dar vieną sezoną, mes...</td>\n",
       "      <td>إذا لعب تيم دنكان موسمًا آخر ، فسنكون قادرين ع...</td>\n",
       "      <td>Pokud by Tim Duncan hrál ještě jednu sezónu, b...</td>\n",
       "      <td>Wenn Tim Duncan noch eine Saison spielte, wäre...</td>\n",
       "      <td>Si Tim Duncan jouait une saison de plus, nous ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>good keep them away from the deplorables Thank...</td>\n",
       "      <td>ለፕሬዚዳንት ኦባማ ለ8 ዓመታት ያህል ሰላም አስገኝቶላቸው ከቆዩት አሳዛኝ...</td>\n",
       "      <td>ካብቲ ፕረዚደንት ኦባማ ን8 ዓመት ዝኣክል ሰላም ጉልባብ ብምግባር ዘስካሕ...</td>\n",
       "      <td>Gerai, kad jie atitolintų nuo išvežamų daiktų,...</td>\n",
       "      <td>من الجيد أن تبقيهم بعيدًا عن المستجدات ، شكرًا...</td>\n",
       "      <td>dobře, držte je dál od deplorables děkuji prez...</td>\n",
       "      <td>Gut, haltet sie von den bedauerlichen Dreieren...</td>\n",
       "      <td>Bon éloigne-les des déplorables merci le prési...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>You were better than my wildest dreams but Im ...</td>\n",
       "      <td>ከህልሜ በላይ ነበርክ ግን ኢም አሁንም ቢሆን ለጦቢ ድሃ ጦቢ ኬት ደስታ ...</td>\n",
       "      <td>ካብ ናይ በረኻ ሕልምታተይ ዝበልጽ እኳ እንተ ኰንካ ፡ ክሳዕ ሕጂ ሕጉስ ...</td>\n",
       "      <td>Tu buvai geresnis už mano laukiškiaus</td>\n",
       "      <td>كنت أفضل من أعنف أحلامي ولكني ما زلت لست سعيدً...</td>\n",
       "      <td>Byl jsi lepší než moje nejdivočejší sny, ale s...</td>\n",
       "      <td>Du warst besser als meine wildesten Träume, ab...</td>\n",
       "      <td>Tu étais meilleur que mes rêves les plus fous ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>Friday Geneva unitednations United Nations Off...</td>\n",
       "      <td>አርብ ጄኔቭ የተባበሩት መንግስታት ድርጅት ጄኔቫ</td>\n",
       "      <td>ዓርቢ ጄኔቫ ኣብ ጀኔቫ ዝርከብ ቤት ፅሕፈት ሕቡራት ሃገራት ሓድነት ዘለዎ...</td>\n",
       "      <td>Penktadienis Ženevos Jungtinių Tautų biuras Že...</td>\n",
       "      <td>يوم الجمعة جنيف الموحد مكتب الأمم المتحدة في جنيف</td>\n",
       "      <td>Pátek Ženevský úřad UnitedNations OSN v Ženevě</td>\n",
       "      <td>Freitag Genfer UnitedNations United Nations Of...</td>\n",
       "      <td>Vendredi Genève Unitednations Office des Natio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7036 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "5511  4 Babette 3 Miss Patty 2 Richard 1 LANE Gilmor...   \n",
       "1487          I guess you need a reading lesson Charlie   \n",
       "5622  if this were true it would be good Because Ass...   \n",
       "1945  probably going to hell for this as well but po...   \n",
       "1250  He didnt fight anything thats his excuse just ...   \n",
       "...                                                 ...   \n",
       "3926  Even though i have my personal beliefs about a...   \n",
       "3231  if tim duncan played one more season we wouldv...   \n",
       "3802  good keep them away from the deplorables Thank...   \n",
       "3298  You were better than my wildest dreams but Im ...   \n",
       "3630  Friday Geneva unitednations United Nations Off...   \n",
       "\n",
       "                                                    AMH  \\\n",
       "5511         4 ባቤት 3 ወይዘሪት ትዕግስት 2 ሪቻርድ 1 ሌን ጊልሞርግልብርቲ4   \n",
       "1487                   የንባብ ትምህርት ቻርሊ እንደሚያስፈልግህ እገምታለሁ   \n",
       "5622  ይህ እውነት ቢሆን ኖሮ አሳንጅ በማሪን ሌ ፔን ኢላማ ላይ ያነጣጠረ በመሆ...   \n",
       "1945  ምናልባትም ይህን ለማድረግ ወደ ሲኦል ቢሄድም ሊቀ ጳጳስ ፍራንሲስ ግን ከ...   \n",
       "1250  ልክ እንደ ቻቬዝ ሰበብ የሆነውን ማንኛውንም ነገር ተጋድሎ አድርጓል ፤ ማ...   \n",
       "...                                                 ...   \n",
       "3926  ፅንስ ስለማስወርድ የግል እምነቴ ቢኖረኝም እንኳ ሌሎች መብቶችን እንደማላ...   \n",
       "3231    አንድ ተጨማሪ ወቅት ላይ ዶንሰን ቢጫወት ኖሮ 21 ክዳን እናስቀምጠው ነበር   \n",
       "3802  ለፕሬዚዳንት ኦባማ ለ8 ዓመታት ያህል ሰላም አስገኝቶላቸው ከቆዩት አሳዛኝ...   \n",
       "3298  ከህልሜ በላይ ነበርክ ግን ኢም አሁንም ቢሆን ለጦቢ ድሃ ጦቢ ኬት ደስታ ...   \n",
       "3630                     አርብ ጄኔቭ የተባበሩት መንግስታት ድርጅት ጄኔቫ   \n",
       "\n",
       "                                               Tigrinya  \\\n",
       "5511            4 ባቤት 3 ወይዘሪት ትዕግስቲ 2 ሪቻርድ 1 ሎምን ጊልሞርጊስ   \n",
       "1487                  ናይ ንባብ ትምህርቲ ከም ዘድልየኻ ይግምት እየ ቻርሊ   \n",
       "5622      ከምኡ እንተ ዝኸውን ነይሩ ፡ ኣሳንጅ ንሓለዋ ባሕሪ ዒላማ ምገበረ ነይሩ   \n",
       "1945  ምናልባት ናብ ሲኦል ምኻድ ከምኡ እውን ጳጳስ ፍራንሲስ ናብ ቫቲካን ፈንጠ...   \n",
       "1250  ምኽኒት ቻቬዝ ፡ ከምኡ ድማ ማዱሮስ ምኽኒት ምስ ኣቕረበ ፡ ነቲ ዘቕረቦ ...   \n",
       "...                                                 ...   \n",
       "3926  ዋላ \"ኳ ብዛዕባ ምንጻል ጥንሲ ውልቃዊ እምነተይ እንተሃለወኒ ፡ ኣብ ልዕ...   \n",
       "3231  ግዜ ዝደኸመ ዳንከን ኣብ ሓደ ወቕቲ እንተ ዝጻወት ፡ 21 መድሓኒ ምበልና...   \n",
       "3802  ካብቲ ፕረዚደንት ኦባማ ን8 ዓመት ዝኣክል ሰላም ጉልባብ ብምግባር ዘስካሕ...   \n",
       "3298  ካብ ናይ በረኻ ሕልምታተይ ዝበልጽ እኳ እንተ ኰንካ ፡ ክሳዕ ሕጂ ሕጉስ ...   \n",
       "3630  ዓርቢ ጄኔቫ ኣብ ጀኔቫ ዝርከብ ቤት ፅሕፈት ሕቡራት ሃገራት ሓድነት ዘለዎ...   \n",
       "\n",
       "                                            Lithaunian   \\\n",
       "5511  4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...   \n",
       "1487        Manau, jums reikia skaitymo pamokos Charlie   \n",
       "5622  Jei tai būtų tiesa, tai būtų gerai, nes Assang...   \n",
       "1945  Tikriausiai taip pat eidami į pragarą, tačiau ...   \n",
       "1250  Jis nieko nekovojo, tai yra jo pasiteisinimas,...   \n",
       "...                                                 ...   \n",
       "3926  Nors aš turiu savo asmeninių įsitikinimų apie ...   \n",
       "3231  Jei Timas Duncanas žaidė dar vieną sezoną, mes...   \n",
       "3802  Gerai, kad jie atitolintų nuo išvežamų daiktų,...   \n",
       "3298              Tu buvai geresnis už mano laukiškiaus   \n",
       "3630  Penktadienis Ženevos Jungtinių Tautų biuras Že...   \n",
       "\n",
       "                                                 Arabic  \\\n",
       "5511  4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...   \n",
       "1487          أعتقد أنك بحاجة إلى درس في القراءة تشارلي   \n",
       "5622  إذا كان هذا صحيحًا ، فسيكون ذلك جيدًا لأن أسان...   \n",
       "1945  من المحتمل أن يذهب إلى الجحيم من أجل هذا أيضًا...   \n",
       "1250  لم يحارب أي شيء هذا عذرا مثلما كان عذر شافيز و...   \n",
       "...                                                 ...   \n",
       "3926  على الرغم من أن لدي معتقداتي الشخصية حول الإجه...   \n",
       "3231  إذا لعب تيم دنكان موسمًا آخر ، فسنكون قادرين ع...   \n",
       "3802  من الجيد أن تبقيهم بعيدًا عن المستجدات ، شكرًا...   \n",
       "3298  كنت أفضل من أعنف أحلامي ولكني ما زلت لست سعيدً...   \n",
       "3630  يوم الجمعة جنيف الموحد مكتب الأمم المتحدة في جنيف   \n",
       "\n",
       "                                                 czech   \\\n",
       "5511  4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...   \n",
       "1487         Myslím, že potřebujete lekci čtení Charlie   \n",
       "5622  Kdyby to byla pravda, bylo by to dobré, protož...   \n",
       "1945  Pravděpodobně za to také chodím do pekla, ale ...   \n",
       "1250  Nebojoval s ničím, co je jeho omluva, stejně j...   \n",
       "...                                                 ...   \n",
       "3926  I když mám své osobní přesvědčení o potratech,...   \n",
       "3231  Pokud by Tim Duncan hrál ještě jednu sezónu, b...   \n",
       "3802  dobře, držte je dál od deplorables děkuji prez...   \n",
       "3298  Byl jsi lepší než moje nejdivočejší sny, ale s...   \n",
       "3630     Pátek Ženevský úřad UnitedNations OSN v Ženevě   \n",
       "\n",
       "                                                Germany  \\\n",
       "5511  4 Babette 3 Fräulein Patty 2 Richard 1 Lane Gi...   \n",
       "1487      Ich denke du brauchst eine Lesestunde Charlie   \n",
       "5622  Wenn dies wahr wäre, wäre es gut, weil Assange...   \n",
       "1945  Wahrscheinlich auch dafür zur Hölle, aber Paps...   \n",
       "1250  Er kämpfte nicht gegen etwas, was seine Entsch...   \n",
       "...                                                 ...   \n",
       "3926  Obwohl ich meine persönlichen Überzeugungen üb...   \n",
       "3231  Wenn Tim Duncan noch eine Saison spielte, wäre...   \n",
       "3802  Gut, haltet sie von den bedauerlichen Dreieren...   \n",
       "3298  Du warst besser als meine wildesten Träume, ab...   \n",
       "3630  Freitag Genfer UnitedNations United Nations Of...   \n",
       "\n",
       "                                                 French  Labels  \n",
       "5511  4 Babette 3 Miss Patty 2 Richard 1 Lane Gilmor...       2  \n",
       "1487  Je suppose que tu as besoin d'une leçon de lec...       0  \n",
       "5622  Si cela était vrai, ce serait bien car Assange...       2  \n",
       "1945  Aller probablement en enfer pour cela aussi, m...       0  \n",
       "1250  Il n'a pas combattu quoi que ce soit, c'est so...       0  \n",
       "...                                                 ...     ...  \n",
       "3926  Même si j'ai mes convictions personnelles sur ...       1  \n",
       "3231  Si Tim Duncan jouait une saison de plus, nous ...       1  \n",
       "3802  Bon éloigne-les des déplorables merci le prési...       1  \n",
       "3298  Tu étais meilleur que mes rêves les plus fous ...       1  \n",
       "3630  Vendredi Genève Unitednations Office des Natio...       1  \n",
       "\n",
       "[7036 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(r'Alllanguages.csv', encoding =\"utf-8\")\n",
    "df = df1.sample(frac =1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264ef68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df.AMH.values.tolist()\n",
    "sentiment = df.Labels.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5877d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = np.array(sentence)\n",
    "sentiment_a =np.array(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86e3f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7036\n",
      "7036\n",
      "[2 0 2 0 0 2 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_a))\n",
    "print(len(sentiment_a))\n",
    "print(sentiment_a[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca12d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comm = []\n",
    "for el in sentence_a:\n",
    "    sent= re.sub(r'[A-Z]+', '', el)\n",
    "    sent1 = re.sub(r'[a-z]+', '',sent)\n",
    "    sent2= re.sub(r'[^\\w]', ' ', sent1)\n",
    "    \n",
    "    Comm.append(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e51ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7036\n",
      "['4 ባቤት 3 ወይዘሪት ትዕግስት 2 ሪቻርድ 1 ሌን ጊልሞርግልብርቲ4', 'የንባብ ትምህርት ቻርሊ እንደሚያስፈልግህ እገምታለሁ', 'ይህ እውነት ቢሆን ኖሮ አሳንጅ በማሪን ሌ ፔን ኢላማ ላይ ያነጣጠረ በመሆኑ ጥሩ ነበር', 'ምናልባትም ይህን ለማድረግ ወደ ሲኦል ቢሄድም ሊቀ ጳጳስ ፍራንሲስ ግን ከቫቲካን ሜሪ ክሪስቲማዎች ጋር የሚያጋጩ አንዳንድ የጅምላ ጭፍጨፋዎች ያስፈልጓቸው ይሆናል', 'ልክ እንደ ቻቬዝ ሰበብ የሆነውን ማንኛውንም ነገር ተጋድሎ አድርጓል   ማዱሮስ ደግሞ ሰበብ አስባብ አቅርቧል', 'ከአንበሳ በግማሽ ማሳረጊያ ላይ ሎል ጀስቲን ግንድ ከበሮ ላይ', 'እስቲ አስቡት ህጻናቱ ቶክሲክ ጭስ ጭስ ጭስ ጭስ ጭስ የሆነውን ሞሱሎፍ ለሕፃናት ጥማት በኢራቅ በኩል ይጫወታሉ', 'ትሬምፕስ መጥፎው ሂላሪ አይ ኤስ የበለጠ የቴፒ ቅንጣት ታህል ለማግኘት ብቁ እንዳልሆነች ቃል የገባውን ቃል ለማየት ብቁ አልሆነም', 'ይህን ግድግዳ ለመሥራት ኪላሪ ድራፍት የተባለውን መጥፎ ማህፀን በሙሉ አፍኖ በማውጣት ልጅ መውለድ ችሏል', 'የሻሮን መርፌዎች ሜላኒያ መለከት እየነፉ ሕዝቡን እያቀጨጩ ነው']\n"
     ]
    }
   ],
   "source": [
    "print(len(Comm))\n",
    "print(Comm[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e6b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "y = np.array(sentiment_a)\n",
    "label_encoder = LabelEncoder()\n",
    "vec = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4575e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n",
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(vec)\n",
    "print(y[1])\n",
    "print(y[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470afd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4502\n",
      "1126\n",
      "1408\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Comm, y , test_size = 0.20, random_state = 42, shuffle = True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.20, random_state = 1, shuffle = True)\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f74eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100000, filters ='!\"#$%&()*+,-./;<=>?@][\\\\]^{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "index_of_words = tokenizer.word_index\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa355b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding = 'post', maxlen = maxlen)\n",
    "X_test = pad_sequences(X_test, padding = 'post', maxlen = maxlen)\n",
    "X_val = pad_sequences(X_val, padding = 'post', maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd00a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 41042 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import pickle \n",
    "with open (\"C:/Users/senug/Documents/Project 1 PHD/EmbeddingAmh.pkl\", 'rb') as f:\n",
    "    embeddings_index = pickle.load(f)\n",
    "    print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a2c59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (300,) into shape (100,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45208/598195763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0membedding_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Embedding matrix shape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (300,) into shape (100,)"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_DIM = 100\n",
    "  \n",
    "embedding_matrix = np.random.random((len(index_of_words) + 1, EMBEDDINGS_DIM))\n",
    "for word, i in index_of_words.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print('Embedding matrix shape', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5779aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1974100   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              234496    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,225,239\n",
      "Trainable params: 251,139\n",
      "Non-trainable params: 1,974,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SpatialDropout1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import LSTM, SpatialDropout1D, Bidirectional\n",
    "from keras.preprocessing import sequence \n",
    "import pandas as pd \n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser \n",
    "from keras import backend as K\n",
    "lstm_out = 196\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights = [embedding_matrix], input_length=maxlen, trainable = False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics =['acc'])\n",
    "model.compile(loss ='categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['acc'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7cffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "36/36 [==============================] - 23s 444ms/step - loss: 1.1068 - acc: 0.3436 - val_loss: 1.1161 - val_acc: 0.3517\n",
      "Epoch 2/50\n",
      "36/36 [==============================] - 15s 407ms/step - loss: 1.0938 - acc: 0.3763 - val_loss: 1.0939 - val_acc: 0.3508\n",
      "Epoch 3/50\n",
      "36/36 [==============================] - 15s 414ms/step - loss: 1.0860 - acc: 0.3896 - val_loss: 1.0939 - val_acc: 0.3517\n",
      "Epoch 4/50\n",
      "36/36 [==============================] - 15s 411ms/step - loss: 1.0863 - acc: 0.3876 - val_loss: 1.0878 - val_acc: 0.3925\n",
      "Epoch 5/50\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 1.0862 - acc: 0.3878 - val_loss: 1.0808 - val_acc: 0.3996\n",
      "Epoch 6/50\n",
      "36/36 [==============================] - 15s 403ms/step - loss: 1.0856 - acc: 0.3894 - val_loss: 1.0785 - val_acc: 0.3996\n",
      "Epoch 7/50\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 1.0788 - acc: 0.4014 - val_loss: 1.0848 - val_acc: 0.3721\n",
      "Epoch 8/50\n",
      "36/36 [==============================] - 14s 397ms/step - loss: 1.0757 - acc: 0.4038 - val_loss: 1.0772 - val_acc: 0.3801\n",
      "Epoch 9/50\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 1.0724 - acc: 0.4158 - val_loss: 1.0671 - val_acc: 0.4290\n",
      "Epoch 10/50\n",
      "36/36 [==============================] - 15s 407ms/step - loss: 1.0648 - acc: 0.4223 - val_loss: 1.0639 - val_acc: 0.4307\n",
      "Epoch 11/50\n",
      "36/36 [==============================] - 15s 417ms/step - loss: 1.0554 - acc: 0.4387 - val_loss: 1.0577 - val_acc: 0.4307\n",
      "Epoch 12/50\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 1.0469 - acc: 0.4429 - val_loss: 1.0539 - val_acc: 0.4210\n",
      "Epoch 13/50\n",
      "36/36 [==============================] - 13s 370ms/step - loss: 1.0465 - acc: 0.4467 - val_loss: 1.0752 - val_acc: 0.4165\n",
      "Epoch 14/50\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 1.0345 - acc: 0.4585 - val_loss: 1.0661 - val_acc: 0.4352\n",
      "Epoch 15/50\n",
      "36/36 [==============================] - 13s 367ms/step - loss: 1.0318 - acc: 0.4574 - val_loss: 1.0567 - val_acc: 0.4192\n",
      "Epoch 16/50\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 1.0242 - acc: 0.4709 - val_loss: 1.0582 - val_acc: 0.4174\n",
      "Epoch 17/50\n",
      "36/36 [==============================] - 14s 405ms/step - loss: 1.0205 - acc: 0.4718 - val_loss: 1.0683 - val_acc: 0.4290\n",
      "Epoch 18/50\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 1.0105 - acc: 0.4929 - val_loss: 1.0905 - val_acc: 0.4290\n",
      "Epoch 19/50\n",
      "36/36 [==============================] - 13s 356ms/step - loss: 1.0075 - acc: 0.4900 - val_loss: 1.0791 - val_acc: 0.4325\n",
      "Epoch 20/50\n",
      "36/36 [==============================] - 13s 358ms/step - loss: 0.9997 - acc: 0.4929 - val_loss: 1.0706 - val_acc: 0.4076\n",
      "Epoch 21/50\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 1.0022 - acc: 0.5016 - val_loss: 1.0714 - val_acc: 0.4121\n",
      "Epoch 22/50\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 0.9833 - acc: 0.5158 - val_loss: 1.0940 - val_acc: 0.4112\n",
      "Epoch 23/50\n",
      "36/36 [==============================] - 14s 389ms/step - loss: 0.9883 - acc: 0.5040 - val_loss: 1.0714 - val_acc: 0.4147\n",
      "Epoch 24/50\n",
      "36/36 [==============================] - 14s 387ms/step - loss: 0.9853 - acc: 0.5109 - val_loss: 1.0745 - val_acc: 0.4290\n",
      "Epoch 25/50\n",
      "36/36 [==============================] - 12s 328ms/step - loss: 0.9728 - acc: 0.5202 - val_loss: 1.1092 - val_acc: 0.4156\n",
      "Epoch 26/50\n",
      "36/36 [==============================] - 13s 355ms/step - loss: 0.9440 - acc: 0.5451 - val_loss: 1.0931 - val_acc: 0.4201\n",
      "Epoch 27/50\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.9333 - acc: 0.5609 - val_loss: 1.1193 - val_acc: 0.4165\n",
      "Epoch 28/50\n",
      "36/36 [==============================] - 14s 383ms/step - loss: 0.9229 - acc: 0.5686 - val_loss: 1.1215 - val_acc: 0.4085\n",
      "Epoch 29/50\n",
      "36/36 [==============================] - 14s 394ms/step - loss: 0.8965 - acc: 0.5871 - val_loss: 1.1340 - val_acc: 0.4174\n",
      "Epoch 30/50\n",
      "36/36 [==============================] - 14s 405ms/step - loss: 0.8792 - acc: 0.5895 - val_loss: 1.1424 - val_acc: 0.4147\n",
      "Epoch 31/50\n",
      "36/36 [==============================] - 13s 376ms/step - loss: 0.8734 - acc: 0.5986 - val_loss: 1.1711 - val_acc: 0.4076\n",
      "Epoch 32/50\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 0.8386 - acc: 0.6177 - val_loss: 1.2952 - val_acc: 0.4112\n",
      "Epoch 33/50\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 0.8791 - acc: 0.5849 - val_loss: 1.1216 - val_acc: 0.4174\n",
      "Epoch 34/50\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.8295 - acc: 0.6202 - val_loss: 1.1735 - val_acc: 0.4210\n",
      "Epoch 35/50\n",
      "36/36 [==============================] - 13s 371ms/step - loss: 0.7774 - acc: 0.6508 - val_loss: 1.2245 - val_acc: 0.4165\n",
      "Epoch 36/50\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 0.7630 - acc: 0.6608 - val_loss: 1.2241 - val_acc: 0.4192\n",
      "Epoch 37/50\n",
      "36/36 [==============================] - 13s 374ms/step - loss: 0.7297 - acc: 0.6808 - val_loss: 1.2225 - val_acc: 0.4378\n",
      "Epoch 38/50\n",
      "36/36 [==============================] - 12s 342ms/step - loss: 0.6923 - acc: 0.6986 - val_loss: 1.2621 - val_acc: 0.4210\n",
      "Epoch 39/50\n",
      "36/36 [==============================] - 13s 363ms/step - loss: 0.6687 - acc: 0.7044 - val_loss: 1.3156 - val_acc: 0.4316\n",
      "Epoch 40/50\n",
      "36/36 [==============================] - 14s 377ms/step - loss: 0.6081 - acc: 0.7406 - val_loss: 1.3721 - val_acc: 0.4103\n",
      "Epoch 41/50\n",
      "36/36 [==============================] - 14s 387ms/step - loss: 0.5577 - acc: 0.7639 - val_loss: 1.4476 - val_acc: 0.4396\n",
      "Epoch 42/50\n",
      "36/36 [==============================] - 14s 392ms/step - loss: 0.5491 - acc: 0.7614 - val_loss: 1.5076 - val_acc: 0.4245\n",
      "Epoch 43/50\n",
      "36/36 [==============================] - 15s 414ms/step - loss: 0.4749 - acc: 0.8030 - val_loss: 1.5405 - val_acc: 0.4227\n",
      "Epoch 44/50\n",
      "36/36 [==============================] - 15s 415ms/step - loss: 0.4720 - acc: 0.8085 - val_loss: 1.6075 - val_acc: 0.4112\n",
      "Epoch 45/50\n",
      "36/36 [==============================] - 13s 372ms/step - loss: 0.4428 - acc: 0.8207 - val_loss: 1.7354 - val_acc: 0.4156\n",
      "Epoch 46/50\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 0.3817 - acc: 0.8481 - val_loss: 1.6936 - val_acc: 0.4103\n",
      "Epoch 47/50\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.3274 - acc: 0.8741 - val_loss: 1.8406 - val_acc: 0.4201\n",
      "Epoch 48/50\n",
      "36/36 [==============================] - 14s 378ms/step - loss: 0.3137 - acc: 0.8798 - val_loss: 1.8565 - val_acc: 0.4210\n",
      "Epoch 49/50\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 0.2537 - acc: 0.9034 - val_loss: 2.0241 - val_acc: 0.4414\n",
      "Epoch 50/50\n",
      "36/36 [==============================] - 14s 405ms/step - loss: 0.2367 - acc: 0.9069 - val_loss: 2.1462 - val_acc: 0.4236\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0.01, patience = 4, verbose = 1)\n",
    "callbacks_list = [early_stopping]\n",
    "hist = model.fit(X_train, y_train, epochs = 50, batch_size =128, verbose = 1, validation_data = (X_val, y_val))\n",
    "#y_test = model.predict(X_test, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c497e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 3s 46ms/step - loss: 2.3811 - acc: 0.3864\n",
      "Test accuracy: 0.3863636255264282\n"
     ]
    }
   ],
   "source": [
    "score,acc  = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43c3b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.938027560710907\n"
     ]
    }
   ],
   "source": [
    "_,train_acc = model.evaluate(X_train,y_train, verbose = 0)\n",
    "print('Train accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1473dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4236234426498413\n"
     ]
    }
   ],
   "source": [
    "a, b = model.evaluate(X_val, y_val, verbose =0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "852edc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 3s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat_probs = model.predict(X_test, verbose = 1)\n",
    "classes_x =np.argmax(yhat_probs, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a800d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 2 1 2 2 2 2 0 1 2 0 0 2 0 2 0 0 0 1 2 1 2 2 2 0 0 1 2 1 1 1 1 1 1 1\n",
      " 0 1 1 2 0 2 0 1 1 1 1 1 0 2 1 2 1 2 0 0 1 1 1 1 2 1 2 0 1 1 1 0 0 1 0 1 2\n",
      " 2 1 2 1 2 2 0 1 1 2 0 1 1 1 1 1 2 1 1 0 1 1 2 1 2 1]\n",
      "[0 2 0 0 1 2 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis =1)\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "print(y_pred[0:100])\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d869b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[139 220 130]\n",
      " [ 92 194 171]\n",
      " [ 92 159 211]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43980319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Positive', 'Neutral', 'Negative']); ax.yaxis.set_ticklabels(['Positive', 'Neutral', 'Negative']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6052e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.28      0.34       489\n",
      "           1       0.34      0.42      0.38       457\n",
      "           2       0.41      0.46      0.43       462\n",
      "\n",
      "    accuracy                           0.39      1408\n",
      "   macro avg       0.39      0.39      0.38      1408\n",
      "weighted avg       0.39      0.39      0.38      1408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077154f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
