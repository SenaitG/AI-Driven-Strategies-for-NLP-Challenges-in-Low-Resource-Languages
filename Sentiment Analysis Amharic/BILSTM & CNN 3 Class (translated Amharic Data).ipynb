{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9be25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re, nltk\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622ad045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>AMH</th>\n",
       "      <th>Tigrinya</th>\n",
       "      <th>Lithaunian</th>\n",
       "      <th>Arabic</th>\n",
       "      <th>czech</th>\n",
       "      <th>Germany</th>\n",
       "      <th>French</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>This new Ted Cruz video is the last Obamacare ...</td>\n",
       "      <td>ይህ አዲሱ ቴድ ክሩዝ ቪዲዮ የኦባራሲያ እውነታው ምን እንደሚፈልግ የሚያሳ...</td>\n",
       "      <td>እዛ ሓዳስ ቴድ ክሩዝ ዘርእስታ ቪድዮ እዚኣ ፡ እታ ኣብ መወዳእታ ዘድልየ...</td>\n",
       "      <td>Šis naujas „Ted Cruz“ vaizdo įrašas yra paskut...</td>\n",
       "      <td>هذا الفيديو الجديد Ted Cruz هو آخر حقيقة أن تح...</td>\n",
       "      <td>Toto nové video Ted Cruz je poslední kontrolou...</td>\n",
       "      <td>Dieses neue Ted Cruz -Video ist das letzte Oba...</td>\n",
       "      <td>Cette nouvelle vidéo Ted Cruz est le dernier v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>Even though i have my personal beliefs about a...</td>\n",
       "      <td>ፅንስ ስለማስወርድ የግል እምነቴ ቢኖረኝም እንኳ ሌሎች መብቶችን እንደማላ...</td>\n",
       "      <td>ዋላ \"ኳ ብዛዕባ ምንጻል ጥንሲ ውልቃዊ እምነተይ እንተሃለወኒ ፡ ኣብ ልዕ...</td>\n",
       "      <td>Nors aš turiu savo asmeninių įsitikinimų apie ...</td>\n",
       "      <td>على الرغم من أن لدي معتقداتي الشخصية حول الإجه...</td>\n",
       "      <td>I když mám své osobní přesvědčení o potratech,...</td>\n",
       "      <td>Obwohl ich meine persönlichen Überzeugungen üb...</td>\n",
       "      <td>Même si j'ai mes convictions personnelles sur ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>When you read this you immediately know it can...</td>\n",
       "      <td>ይህን ስታነብ እውነተኛ ክርስትያኖ ሮናልዶ ለእንግሊዝ ድንግል ደሴቶች ሲት...</td>\n",
       "      <td>ነዚ ብኡንብኡ ምስ ኣንበብካዮ ናይ ሓቂ ክሪስቲያኖ ሮናልዶ ነቲ ገንዘብ ሲ...</td>\n",
       "      <td>Kai perskaitysite tai, tuoj pat žinote</td>\n",
       "      <td>عندما تقرأ هذا ، فأنت تعرف أنه لا يمكن أن يكون...</td>\n",
       "      <td>Když si to přečtete, okamžitě víte, že to nemů...</td>\n",
       "      <td>Wenn Sie dies lesen, wissen Sie sofort</td>\n",
       "      <td>Lorsque vous lisez ceci, vous savez immédiatem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>Fidel Castros African legacy Friendship and fr...</td>\n",
       "      <td>ፊደል የአፍሪካ ቅርስ ወዳጅነትና ነፃነት</td>\n",
       "      <td>ፊደል ካስትሮስ ኣፍሪቃዊ ውርሻ ምሕዝነትን ሓርነትን</td>\n",
       "      <td>Fidelis Castrosas Afrikos palikimo draugystė i...</td>\n",
       "      <td>فيدل كاستروس الصداقة الحرية الحرية فيدل كاستروس</td>\n",
       "      <td>Fidel Castros africké dědictví přátelství a sv...</td>\n",
       "      <td>Fidel Castros afrikanische Legacy -Freundschaf...</td>\n",
       "      <td>Fidel Castros African Héritage Amitié et liberté</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>Data collecting jobs can be automated 64 and d...</td>\n",
       "      <td>የውሂብ መሰብሰብ ስራዎች በማኪንሲ በኩል 69 በሆነ መንገድ 64 እና የዳ...</td>\n",
       "      <td>ናይ ሓበሬታ ምእካብ ስራሕ ብመኪና 64 ከምኡ \"ውን ናይ ሓበሬታ መስርሕ ...</td>\n",
       "      <td>Duomenų rinkimo darbai gali būti automatizuoti...</td>\n",
       "      <td>يمكن أن تكون وظائف جمع البيانات تلقائيًا 64 وظ...</td>\n",
       "      <td>Úkoly pro sběr dat mohou být automatizovány 64...</td>\n",
       "      <td>Daten sammeln Jobs können laut McKinsey via Mc...</td>\n",
       "      <td>Les travaux de collecte de données peuvent êtr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>The press are too critical of Pres Elect Trump...</td>\n",
       "      <td>ፕሬዘዳንቶች ለመጀመሪያዎቹ 2 ሳምንታት የኤሌክትራ ትራምፕ የሽግግር ሚዲያ...</td>\n",
       "      <td>ማዕከናት ዜና ኣዝዩ ነቓፊ እዩ ፡ ኤለክትር ትራምፕ ኣብተን ናይ መጀመርታ...</td>\n",
       "      <td>Spauda per daug kritiškai vertina „Pres“ išrin...</td>\n",
       "      <td>الصحافة تنتقد للغاية Pres Elect Trump التي قام...</td>\n",
       "      <td>Tisk je příliš kritický vůči Pred Trump, že pr...</td>\n",
       "      <td>Die Presse ist zu kritisch gegenüber Pres Elec...</td>\n",
       "      <td>La presse est trop critique à l'égard de Pres ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>Messi FCBLive thr are two clubs in the world F...</td>\n",
       "      <td>ሜሲ ብለድሊቭ በዓለም ላይ ኖርቨርፑል እና ሌሎቹም ክለቦች ናቸው</td>\n",
       "      <td>መሲ.ቢ.ሲ.ኣይ. ዘርእስተን ክልተ ክለባት ዓለም ፡ እተን ካልኦት ከኣ ከ...</td>\n",
       "      <td>Messi fcblive Thr yra du klubai pasaulyje FCB ...</td>\n",
       "      <td>Messi fcblive thr ناديان في العالم FCB والآخرين</td>\n",
       "      <td>Messi fcblive Thr jsou dva kluby na světě FCB ...</td>\n",
       "      <td>Messi fcblive thr sind zwei Clubs der Welt FCB...</td>\n",
       "      <td>Messi fcblive thr est deux clubs dans le monde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Tell to reduce their animal testing they KILL ...</td>\n",
       "      <td>የእንስሳትን ምርመራ ለመቀነስ በየቀኑ 226 ኤማዎችን መግደላቸውን ተናገሩ</td>\n",
       "      <td>ናይ እንስሳ መመርመሪኦም ንምቕናስ ፡ ንሓንቲ መዓልቲ 226 ANMA</td>\n",
       "      <td>Liepkite sumažinti jų bandymus su gyvūnais, ji...</td>\n",
       "      <td>أخبر بتقليل اختبار الحيوانات الخاص بهم أنهم يق...</td>\n",
       "      <td>Řekněte, aby snížili své testování zvířat, zab...</td>\n",
       "      <td>Sagen Sie, dass sie ihre Tiertests reduzieren,...</td>\n",
       "      <td>Dites de réduire leurs tests animaux, ils tuen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>OMG Nialls eyes o 3MPN OneDirection</td>\n",
       "      <td>Omg ኋይኖች OMPN OneDrive</td>\n",
       "      <td>ኦ ኤም ጂ ንኣዒንቲ ኣፍንጭኣ 3MPN ሓደ ዓይነት</td>\n",
       "      <td>Omg nialls akys o 3Mpn onedirection</td>\n",
       "      <td>OMG Nialls Eyes o 3mpn onedirection</td>\n",
       "      <td>Omg nialls oči o 3mpn oneDirection</td>\n",
       "      <td>Omg nialls Augen der 3mpn -OneDirection</td>\n",
       "      <td>Omg nialls yeux o 3mpn onirection</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>watching this david blaine shit on netflix and...</td>\n",
       "      <td>ይህን ዴቪድ ፊኛ በመረብ ነቀለ እና ይህ ኤም ኤፍ እብድ ነው</td>\n",
       "      <td>ዳዊት ነዚ ምስ ረአየ ኣብ ኣፍ መርበብ ሓበረ: እዚ ኤም ኤፍ እዚ ድማ ዕ...</td>\n",
       "      <td>Stebėti šį Davido Blaine'o šūdą „Netflix“ ir š...</td>\n",
       "      <td>مشاهدة هذا القرف ديفيد بلين على Netflix وهذا M...</td>\n",
       "      <td>Sledování tohoto Davida Blaineho hovno na Netf...</td>\n",
       "      <td>Ich schaue diesen David Blaine -Scheiß auf Net...</td>\n",
       "      <td>Regarder cette merde de David Blaine sur Netfl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7036 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "3580  This new Ted Cruz video is the last Obamacare ...   \n",
       "3926  Even though i have my personal beliefs about a...   \n",
       "2629  When you read this you immediately know it can...   \n",
       "2908  Fidel Castros African legacy Friendship and fr...   \n",
       "4358  Data collecting jobs can be automated 64 and d...   \n",
       "...                                                 ...   \n",
       "2910  The press are too critical of Pres Elect Trump...   \n",
       "4072  Messi FCBLive thr are two clubs in the world F...   \n",
       "970   Tell to reduce their animal testing they KILL ...   \n",
       "6509                OMG Nialls eyes o 3MPN OneDirection   \n",
       "249   watching this david blaine shit on netflix and...   \n",
       "\n",
       "                                                    AMH  \\\n",
       "3580  ይህ አዲሱ ቴድ ክሩዝ ቪዲዮ የኦባራሲያ እውነታው ምን እንደሚፈልግ የሚያሳ...   \n",
       "3926  ፅንስ ስለማስወርድ የግል እምነቴ ቢኖረኝም እንኳ ሌሎች መብቶችን እንደማላ...   \n",
       "2629  ይህን ስታነብ እውነተኛ ክርስትያኖ ሮናልዶ ለእንግሊዝ ድንግል ደሴቶች ሲት...   \n",
       "2908                          ፊደል የአፍሪካ ቅርስ ወዳጅነትና ነፃነት   \n",
       "4358  የውሂብ መሰብሰብ ስራዎች በማኪንሲ በኩል 69 በሆነ መንገድ 64 እና የዳ...   \n",
       "...                                                 ...   \n",
       "2910  ፕሬዘዳንቶች ለመጀመሪያዎቹ 2 ሳምንታት የኤሌክትራ ትራምፕ የሽግግር ሚዲያ...   \n",
       "4072           ሜሲ ብለድሊቭ በዓለም ላይ ኖርቨርፑል እና ሌሎቹም ክለቦች ናቸው   \n",
       "970      የእንስሳትን ምርመራ ለመቀነስ በየቀኑ 226 ኤማዎችን መግደላቸውን ተናገሩ   \n",
       "6509                             Omg ኋይኖች OMPN OneDrive   \n",
       "249              ይህን ዴቪድ ፊኛ በመረብ ነቀለ እና ይህ ኤም ኤፍ እብድ ነው   \n",
       "\n",
       "                                               Tigrinya  \\\n",
       "3580  እዛ ሓዳስ ቴድ ክሩዝ ዘርእስታ ቪድዮ እዚኣ ፡ እታ ኣብ መወዳእታ ዘድልየ...   \n",
       "3926  ዋላ \"ኳ ብዛዕባ ምንጻል ጥንሲ ውልቃዊ እምነተይ እንተሃለወኒ ፡ ኣብ ልዕ...   \n",
       "2629  ነዚ ብኡንብኡ ምስ ኣንበብካዮ ናይ ሓቂ ክሪስቲያኖ ሮናልዶ ነቲ ገንዘብ ሲ...   \n",
       "2908                   ፊደል ካስትሮስ ኣፍሪቃዊ ውርሻ ምሕዝነትን ሓርነትን   \n",
       "4358  ናይ ሓበሬታ ምእካብ ስራሕ ብመኪና 64 ከምኡ \"ውን ናይ ሓበሬታ መስርሕ ...   \n",
       "...                                                 ...   \n",
       "2910  ማዕከናት ዜና ኣዝዩ ነቓፊ እዩ ፡ ኤለክትር ትራምፕ ኣብተን ናይ መጀመርታ...   \n",
       "4072  መሲ.ቢ.ሲ.ኣይ. ዘርእስተን ክልተ ክለባት ዓለም ፡ እተን ካልኦት ከኣ ከ...   \n",
       "970          ናይ እንስሳ መመርመሪኦም ንምቕናስ ፡ ንሓንቲ መዓልቲ 226 ANMA   \n",
       "6509                    ኦ ኤም ጂ ንኣዒንቲ ኣፍንጭኣ 3MPN ሓደ ዓይነት   \n",
       "249   ዳዊት ነዚ ምስ ረአየ ኣብ ኣፍ መርበብ ሓበረ: እዚ ኤም ኤፍ እዚ ድማ ዕ...   \n",
       "\n",
       "                                            Lithaunian   \\\n",
       "3580  Šis naujas „Ted Cruz“ vaizdo įrašas yra paskut...   \n",
       "3926  Nors aš turiu savo asmeninių įsitikinimų apie ...   \n",
       "2629             Kai perskaitysite tai, tuoj pat žinote   \n",
       "2908  Fidelis Castrosas Afrikos palikimo draugystė i...   \n",
       "4358  Duomenų rinkimo darbai gali būti automatizuoti...   \n",
       "...                                                 ...   \n",
       "2910  Spauda per daug kritiškai vertina „Pres“ išrin...   \n",
       "4072  Messi fcblive Thr yra du klubai pasaulyje FCB ...   \n",
       "970   Liepkite sumažinti jų bandymus su gyvūnais, ji...   \n",
       "6509                Omg nialls akys o 3Mpn onedirection   \n",
       "249   Stebėti šį Davido Blaine'o šūdą „Netflix“ ir š...   \n",
       "\n",
       "                                                 Arabic  \\\n",
       "3580  هذا الفيديو الجديد Ted Cruz هو آخر حقيقة أن تح...   \n",
       "3926  على الرغم من أن لدي معتقداتي الشخصية حول الإجه...   \n",
       "2629  عندما تقرأ هذا ، فأنت تعرف أنه لا يمكن أن يكون...   \n",
       "2908    فيدل كاستروس الصداقة الحرية الحرية فيدل كاستروس   \n",
       "4358  يمكن أن تكون وظائف جمع البيانات تلقائيًا 64 وظ...   \n",
       "...                                                 ...   \n",
       "2910  الصحافة تنتقد للغاية Pres Elect Trump التي قام...   \n",
       "4072    Messi fcblive thr ناديان في العالم FCB والآخرين   \n",
       "970   أخبر بتقليل اختبار الحيوانات الخاص بهم أنهم يق...   \n",
       "6509                OMG Nialls Eyes o 3mpn onedirection   \n",
       "249   مشاهدة هذا القرف ديفيد بلين على Netflix وهذا M...   \n",
       "\n",
       "                                                 czech   \\\n",
       "3580  Toto nové video Ted Cruz je poslední kontrolou...   \n",
       "3926  I když mám své osobní přesvědčení o potratech,...   \n",
       "2629  Když si to přečtete, okamžitě víte, že to nemů...   \n",
       "2908  Fidel Castros africké dědictví přátelství a sv...   \n",
       "4358  Úkoly pro sběr dat mohou být automatizovány 64...   \n",
       "...                                                 ...   \n",
       "2910  Tisk je příliš kritický vůči Pred Trump, že pr...   \n",
       "4072  Messi fcblive Thr jsou dva kluby na světě FCB ...   \n",
       "970   Řekněte, aby snížili své testování zvířat, zab...   \n",
       "6509                 Omg nialls oči o 3mpn oneDirection   \n",
       "249   Sledování tohoto Davida Blaineho hovno na Netf...   \n",
       "\n",
       "                                                Germany  \\\n",
       "3580  Dieses neue Ted Cruz -Video ist das letzte Oba...   \n",
       "3926  Obwohl ich meine persönlichen Überzeugungen üb...   \n",
       "2629             Wenn Sie dies lesen, wissen Sie sofort   \n",
       "2908  Fidel Castros afrikanische Legacy -Freundschaf...   \n",
       "4358  Daten sammeln Jobs können laut McKinsey via Mc...   \n",
       "...                                                 ...   \n",
       "2910  Die Presse ist zu kritisch gegenüber Pres Elec...   \n",
       "4072  Messi fcblive thr sind zwei Clubs der Welt FCB...   \n",
       "970   Sagen Sie, dass sie ihre Tiertests reduzieren,...   \n",
       "6509            Omg nialls Augen der 3mpn -OneDirection   \n",
       "249   Ich schaue diesen David Blaine -Scheiß auf Net...   \n",
       "\n",
       "                                                 French  Labels  \n",
       "3580  Cette nouvelle vidéo Ted Cruz est le dernier v...       1  \n",
       "3926  Même si j'ai mes convictions personnelles sur ...       1  \n",
       "2629  Lorsque vous lisez ceci, vous savez immédiatem...       1  \n",
       "2908   Fidel Castros African Héritage Amitié et liberté       1  \n",
       "4358  Les travaux de collecte de données peuvent êtr...       1  \n",
       "...                                                 ...     ...  \n",
       "2910  La presse est trop critique à l'égard de Pres ...       1  \n",
       "4072  Messi fcblive thr est deux clubs dans le monde...       1  \n",
       "970   Dites de réduire leurs tests animaux, ils tuen...       0  \n",
       "6509                  Omg nialls yeux o 3mpn onirection       2  \n",
       "249   Regarder cette merde de David Blaine sur Netfl...       0  \n",
       "\n",
       "[7036 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(r'Alllanguages.csv', encoding =\"utf-8\")\n",
    "df = df1.sample(frac =1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1299cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df.AMH.values.tolist()\n",
    "sentiment = df.Labels.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4c46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = np.array(sentence)\n",
    "sentiment_a =np.array(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde590f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7036\n",
      "7036\n",
      "[1 1 1 1 1 1 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_a))\n",
    "print(len(sentiment_a))\n",
    "print(sentiment_a[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d279e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comm = []\n",
    "for el in sentence_a:\n",
    "    sent= re.sub(r'[A-Z]+', '', el)\n",
    "    sent1 = re.sub(r'[a-z]+', '',sent)\n",
    "    sent2= re.sub(r'[^\\w]', ' ', sent1)\n",
    "    \n",
    "    Comm.append(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a89473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7036\n",
      "['ይህ አዲሱ ቴድ ክሩዝ ቪዲዮ የኦባራሲያ እውነታው ምን እንደሚፈልግ የሚያሳይ የመጨረሻው ቪዲዮ ነው', 'ፅንስ ስለማስወርድ የግል እምነቴ ቢኖረኝም እንኳ ሌሎች መብቶችን እንደማላከብር አውቃለሁ', 'ይህን ስታነብ እውነተኛ ክርስትያኖ ሮናልዶ ለእንግሊዝ ድንግል ደሴቶች ሲትራግራይት የተባለውን ገንዘብ አሰባስቦ ነበር', 'ፊደል የአፍሪካ ቅርስ ወዳጅነትና ነፃነት', 'የውሂብ መሰብሰብ ስራዎች በማኪንሲ በኩል 69 በሆነ መንገድ 64 እና የዳታ ፕሮሰሲንግ ስራዎችን በራስ ሰር መስራት ይቻላል', 'የዩክሬን ኤውዛ በቅርቡ ይሻራል', 'ቫኔሳ ሁድገንስ ሳይል በዛክሮን ቪድዮ ኦክ ሙዚቃዊ ኦክላይን ሊ ኩሊቴ', 'ማንኒኩዊንቻሌግ በትርግትዝ በኩል በዱንሃም መንገድ ቅርጽ ባለው መንገድ ቅርጽ አውጪ ዳውንሃምፍቶችን የሠራበትን ቀን ማሸነፍ', 'በእርሱ ካመናችሁበት ቪዲዮ ይመልከቱ', 'ጆርጅ ሶሮስ የተሰኘ አዲስ ግሪንዳይ የተሰኘ አልበም ጭንቅላቴ ላይ ጠጉር ሰክቶ ፍቅርን ወደ ፊት ገጠመኝ']\n"
     ]
    }
   ],
   "source": [
    "print(len(Comm))\n",
    "print(Comm[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b74ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "y = np.array(sentiment_a)\n",
    "label_encoder = LabelEncoder()\n",
    "vec = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9922c1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0.]\n",
      "[0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(vec)\n",
    "print(y[1])\n",
    "print(y[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb320fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4502\n",
      "1126\n",
      "1408\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Comm, y , test_size = 0.20, random_state = 42, shuffle = True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.20, random_state = 1, shuffle = True)\n",
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0963fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100000, filters ='!\"#$%&()*+,-./;<=>?@][\\\\]^{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "index_of_words = tokenizer.word_index\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d79ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding = 'post', maxlen = maxlen)\n",
    "X_test = pad_sequences(X_test, padding = 'post', maxlen = maxlen)\n",
    "X_val = pad_sequences(X_val, padding = 'post', maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a466297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 41042 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import pickle \n",
    "with open (\"C:/Users/senug/Documents/Project 1 PHD/EmbeddingAmh.pkl\", 'rb') as f:\n",
    "    embeddings_index = pickle.load(f)\n",
    "    print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104e14db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape (19741, 300)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_DIM = 300\n",
    "  \n",
    "embedding_matrix = np.random.random((len(index_of_words) + 1, EMBEDDINGS_DIM))\n",
    "for word, i in index_of_words.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print('Embedding matrix shape', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9097a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 300)          5922300   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 100, 128)          115328    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 50, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 50, 128)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,169,599\n",
      "Trainable params: 247,299\n",
      "Non-trainable params: 5,922,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SpatialDropout1D, Bidirectional\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.preprocessing import sequence \n",
    "import pandas as pd \n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser \n",
    "from keras import backend as K\n",
    "lstm_out = 196\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 300, weights = [embedding_matrix], input_length=maxlen, trainable = False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters = 128, kernel_size =3, padding ='same', activation ='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(128, dropout = 0.2, recurrent_dropout= 0.2))\n",
    "model.add(Dense(3, activation = 'sigmoid'))\n",
    "model.compile(loss ='categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['acc'])\n",
    "print(model.summary())\n",
    "#model.add(Conv1D(128,5, activation = 'relu'))\n",
    "#model.add(GlobalMaxPooling1D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(64,activation = 'relu'))\n",
    "#model.add(Dense(4, activation ='sigmoid'))\n",
    "#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e4e7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 15s 266ms/step - loss: 1.1328 - acc: 0.3327 - val_loss: 1.1000 - val_acc: 0.3313\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 10s 269ms/step - loss: 1.1086 - acc: 0.3461 - val_loss: 1.1317 - val_acc: 0.3357\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 1.1125 - acc: 0.3345 - val_loss: 1.1030 - val_acc: 0.3357\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 1.1061 - acc: 0.3334 - val_loss: 1.0988 - val_acc: 0.3330\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 10s 282ms/step - loss: 1.1050 - acc: 0.3372 - val_loss: 1.1101 - val_acc: 0.3330\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 8s 233ms/step - loss: 1.1066 - acc: 0.3341 - val_loss: 1.1006 - val_acc: 0.3357\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 1.1047 - acc: 0.3212 - val_loss: 1.1022 - val_acc: 0.3330\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 9s 251ms/step - loss: 1.1036 - acc: 0.3299 - val_loss: 1.1056 - val_acc: 0.3330\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 1.1039 - acc: 0.3292 - val_loss: 1.1000 - val_acc: 0.3330\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 1.1030 - acc: 0.3212 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 9s 236ms/step - loss: 1.1014 - acc: 0.3236 - val_loss: 1.0998 - val_acc: 0.3330\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 10s 282ms/step - loss: 1.1027 - acc: 0.3301 - val_loss: 1.1000 - val_acc: 0.3313\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 9s 238ms/step - loss: 1.1015 - acc: 0.3339 - val_loss: 1.1049 - val_acc: 0.3313\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 10s 264ms/step - loss: 1.1009 - acc: 0.3367 - val_loss: 1.1000 - val_acc: 0.3313\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.1026 - acc: 0.3236 - val_loss: 1.1005 - val_acc: 0.3313\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 1.1017 - acc: 0.3405 - val_loss: 1.0988 - val_acc: 0.3357\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 10s 273ms/step - loss: 1.1018 - acc: 0.3272 - val_loss: 1.0995 - val_acc: 0.3357\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 9s 239ms/step - loss: 1.1012 - acc: 0.3314 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 1.1016 - acc: 0.3190 - val_loss: 1.0991 - val_acc: 0.3357\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 9s 255ms/step - loss: 1.1011 - acc: 0.3272 - val_loss: 1.0986 - val_acc: 0.3330\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 1.1008 - acc: 0.3299 - val_loss: 1.0992 - val_acc: 0.3330\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 1.0995 - acc: 0.3412 - val_loss: 1.1005 - val_acc: 0.3330\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 9s 245ms/step - loss: 1.0990 - acc: 0.3361 - val_loss: 1.0992 - val_acc: 0.3330\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 10s 282ms/step - loss: 1.1002 - acc: 0.3398 - val_loss: 1.1010 - val_acc: 0.3313\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 1.1006 - acc: 0.3376 - val_loss: 1.0992 - val_acc: 0.3313\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 10s 265ms/step - loss: 1.1000 - acc: 0.3403 - val_loss: 1.1002 - val_acc: 0.3330\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 1.0998 - acc: 0.3323 - val_loss: 1.0997 - val_acc: 0.3313\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.0997 - acc: 0.3305 - val_loss: 1.0991 - val_acc: 0.3313\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 10s 284ms/step - loss: 1.1000 - acc: 0.3354 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 9s 238ms/step - loss: 1.1006 - acc: 0.3314 - val_loss: 1.0996 - val_acc: 0.3330\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 1.1000 - acc: 0.3383 - val_loss: 1.0993 - val_acc: 0.3313\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 9s 259ms/step - loss: 1.1003 - acc: 0.3261 - val_loss: 1.0989 - val_acc: 0.3330\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 9s 257ms/step - loss: 1.1001 - acc: 0.3316 - val_loss: 1.0991 - val_acc: 0.3313\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 10s 281ms/step - loss: 1.0994 - acc: 0.3341 - val_loss: 1.0992 - val_acc: 0.3313\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 9s 242ms/step - loss: 1.0988 - acc: 0.3394 - val_loss: 1.0991 - val_acc: 0.3313\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 10s 284ms/step - loss: 1.1004 - acc: 0.3272 - val_loss: 1.1005 - val_acc: 0.3330\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 9s 257ms/step - loss: 1.0995 - acc: 0.3418 - val_loss: 1.0990 - val_acc: 0.3330\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 1.1013 - acc: 0.3205 - val_loss: 1.0991 - val_acc: 0.3313\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 10s 281ms/step - loss: 1.0991 - acc: 0.3432 - val_loss: 1.0986 - val_acc: 0.3357\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 9s 244ms/step - loss: 1.1003 - acc: 0.3285 - val_loss: 1.0993 - val_acc: 0.3313\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 10s 285ms/step - loss: 1.0994 - acc: 0.3312 - val_loss: 1.1000 - val_acc: 0.3330\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 9s 255ms/step - loss: 1.0986 - acc: 0.3272 - val_loss: 1.0986 - val_acc: 0.3357\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 9s 263ms/step - loss: 1.1003 - acc: 0.3310 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 1.0996 - acc: 0.3359 - val_loss: 1.0987 - val_acc: 0.3357\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 9s 245ms/step - loss: 1.1001 - acc: 0.3312 - val_loss: 1.0992 - val_acc: 0.3313\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 10s 287ms/step - loss: 1.0994 - acc: 0.3274 - val_loss: 1.0986 - val_acc: 0.3330\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 9s 246ms/step - loss: 1.0998 - acc: 0.3185 - val_loss: 1.0989 - val_acc: 0.3330\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 1.0991 - acc: 0.3414 - val_loss: 1.0990 - val_acc: 0.3313\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 10s 271ms/step - loss: 1.0992 - acc: 0.3287 - val_loss: 1.0990 - val_acc: 0.3313\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 1.0998 - acc: 0.3323 - val_loss: 1.0993 - val_acc: 0.3330\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 10s 289ms/step - loss: 1.0999 - acc: 0.3272 - val_loss: 1.0997 - val_acc: 0.3313\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 9s 247ms/step - loss: 1.1000 - acc: 0.3219 - val_loss: 1.0993 - val_acc: 0.3357\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 10s 271ms/step - loss: 1.0992 - acc: 0.3303 - val_loss: 1.0993 - val_acc: 0.3313\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.1001 - acc: 0.3174 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 1.0991 - acc: 0.3290 - val_loss: 1.0994 - val_acc: 0.3330\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 10s 292ms/step - loss: 1.0997 - acc: 0.3356 - val_loss: 1.0987 - val_acc: 0.3313\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 9s 249ms/step - loss: 1.0982 - acc: 0.3374 - val_loss: 1.0987 - val_acc: 0.3357\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 10s 279ms/step - loss: 1.1006 - acc: 0.3325 - val_loss: 1.1007 - val_acc: 0.3330\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 10s 267ms/step - loss: 1.0996 - acc: 0.3252 - val_loss: 1.0989 - val_acc: 0.3330\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 9s 253ms/step - loss: 1.0995 - acc: 0.3261 - val_loss: 1.1000 - val_acc: 0.3330\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 10s 280ms/step - loss: 1.0994 - acc: 0.3361 - val_loss: 1.0989 - val_acc: 0.3313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 1.0988 - acc: 0.3407 - val_loss: 1.0990 - val_acc: 0.3330\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 1.0997 - acc: 0.3230 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 1.0987 - acc: 0.3387 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 1.0992 - acc: 0.3396 - val_loss: 1.0987 - val_acc: 0.3330\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 10s 276ms/step - loss: 1.0989 - acc: 0.3281 - val_loss: 1.0994 - val_acc: 0.3313\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 9s 243ms/step - loss: 1.0990 - acc: 0.3363 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 10s 283ms/step - loss: 1.0982 - acc: 0.3494 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.0998 - acc: 0.3418 - val_loss: 1.0992 - val_acc: 0.3313\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 1.0997 - acc: 0.3247 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 10s 273ms/step - loss: 1.0996 - acc: 0.3290 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 9s 245ms/step - loss: 1.0989 - acc: 0.3294 - val_loss: 1.0990 - val_acc: 0.3330\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 10s 290ms/step - loss: 1.0987 - acc: 0.3274 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.0996 - acc: 0.3223 - val_loss: 1.0988 - val_acc: 0.3330\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 10s 267ms/step - loss: 1.0986 - acc: 0.3365 - val_loss: 1.0988 - val_acc: 0.3330\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 1.0985 - acc: 0.3425 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.0988 - acc: 0.3250 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 10s 292ms/step - loss: 1.0990 - acc: 0.3350 - val_loss: 1.0987 - val_acc: 0.3330\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 9s 241ms/step - loss: 1.0983 - acc: 0.3387 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 10s 270ms/step - loss: 1.0986 - acc: 0.3290 - val_loss: 1.0990 - val_acc: 0.3330\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 9s 262ms/step - loss: 1.0998 - acc: 0.3436 - val_loss: 1.0987 - val_acc: 0.3313\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 1.0988 - acc: 0.3332 - val_loss: 1.0986 - val_acc: 0.3330\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 10s 287ms/step - loss: 1.0989 - acc: 0.3367 - val_loss: 1.0989 - val_acc: 0.3330\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 9s 244ms/step - loss: 1.0988 - acc: 0.3376 - val_loss: 1.0987 - val_acc: 0.3330\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 10s 279ms/step - loss: 1.0985 - acc: 0.3245 - val_loss: 1.0987 - val_acc: 0.3330\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 1.0990 - acc: 0.3281 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 9s 248ms/step - loss: 1.0988 - acc: 0.3223 - val_loss: 1.0987 - val_acc: 0.3330\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 10s 283ms/step - loss: 1.0982 - acc: 0.3367 - val_loss: 1.0987 - val_acc: 0.3330\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 9s 240ms/step - loss: 1.0986 - acc: 0.3363 - val_loss: 1.0986 - val_acc: 0.3330\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 10s 280ms/step - loss: 1.0994 - acc: 0.3367 - val_loss: 1.0987 - val_acc: 0.3313\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 9s 264ms/step - loss: 1.0984 - acc: 0.3423 - val_loss: 1.0991 - val_acc: 0.3313\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 9s 256ms/step - loss: 1.0986 - acc: 0.3474 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 10s 282ms/step - loss: 1.0987 - acc: 0.3341 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 9s 237ms/step - loss: 1.0982 - acc: 0.3378 - val_loss: 1.0991 - val_acc: 0.3330\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 1.0983 - acc: 0.3378 - val_loss: 1.0990 - val_acc: 0.3330\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 1.0987 - acc: 0.3430 - val_loss: 1.0989 - val_acc: 0.3313\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 10s 264ms/step - loss: 1.0997 - acc: 0.3336 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 10s 273ms/step - loss: 1.0983 - acc: 0.3352 - val_loss: 1.0988 - val_acc: 0.3313\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 9s 239ms/step - loss: 1.0989 - acc: 0.3365 - val_loss: 1.0986 - val_acc: 0.3313\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 10s 291ms/step - loss: 1.0984 - acc: 0.3367 - val_loss: 1.0987 - val_acc: 0.3313\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0.01, patience = 4, verbose = 1)\n",
    "callbacks_list = [early_stopping]\n",
    "hist = model.fit(X_train, y_train, epochs = 100, batch_size =128, verbose = 1, validation_data = (X_val, y_val))\n",
    "#y_test = model.predict(X_test, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a9ee07c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1473, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 1) and (32, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37492/2892894885.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1473, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\senug\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 1) and (32, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "score,acc  = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,train_acc = model.evaluate(X_train,y_train, verbose = 0)\n",
    "print('Train accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = model.evaluate(X_val, y_val, verbose =0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(X_test, verbose = 1)\n",
    "classes_x =np.argmax(yhat_probs, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da12edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis =1)\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "print(y_pred[0:100])\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd261291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "\n",
    "ax= plt.subplot()\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Positive', 'Neutral', 'Negative']); ax.yaxis.set_ticklabels(['Positive', 'Neutral', 'Negative']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c33ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
